{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128716 train + 32179 test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_path='data9.csv'\n",
    "data= pd.read_csv(\"data9.csv\", dtype=float)\n",
    "data=data.dropna(axis=0,how='any')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = train_set.drop(['d1prec','d2prec','prec','d1ndvi','d2ndvi','ndvi','d1temp','d2temp','temp','evapot','elevation','soilmo','phreat','gwlvl','truth'], axis=1)\n",
    "Y_training = train_set [['phreat']].values\n",
    "X_testing = test_set.drop(['d1prec','d2prec','prec','d1ndvi','d2ndvi','ndvi','d1temp','d2temp','temp','evapot','elevation','soilmo','phreat','gwlvl','truth'], axis=1)\n",
    "Y_testing = test_set [['phreat']].values\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128716, 17)\n",
      "(128716, 1)\n",
      "(32179, 17)\n",
      "(32179, 1)\n",
      "Note: Y values were scaled by multiplying by 0.0022438313 and adding 0.2196\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled_training.shape)\n",
    "print(Y_scaled_training.shape)\n",
    "\n",
    "print(X_scaled_testing.shape)\n",
    "print(Y_scaled_testing.shape)\n",
    "\n",
    "print(\"Note: Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0], Y_scaler.min_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>d1sat0</th>\n",
       "      <th>d2sat0</th>\n",
       "      <th>sat0</th>\n",
       "      <th>d1sat1</th>\n",
       "      <th>d2sat1</th>\n",
       "      <th>sat1</th>\n",
       "      <th>d1sat2</th>\n",
       "      <th>d2sat2</th>\n",
       "      <th>sat2</th>\n",
       "      <th>d1sat3</th>\n",
       "      <th>d2sat3</th>\n",
       "      <th>sat3</th>\n",
       "      <th>d1sat4</th>\n",
       "      <th>d2sat4</th>\n",
       "      <th>sat4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86881</th>\n",
       "      <td>374.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>-1.4649</td>\n",
       "      <td>-81.3611</td>\n",
       "      <td>1388.5</td>\n",
       "      <td>-5.0537</td>\n",
       "      <td>-166.5000</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>-7.7735</td>\n",
       "      <td>-224.6389</td>\n",
       "      <td>2602.0</td>\n",
       "      <td>-28.4794</td>\n",
       "      <td>-300.2500</td>\n",
       "      <td>2783.5</td>\n",
       "      <td>-6.1192</td>\n",
       "      <td>-246.1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>1.4959</td>\n",
       "      <td>63.4167</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>1.3194</td>\n",
       "      <td>72.0833</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1.4102</td>\n",
       "      <td>69.5278</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1.0335</td>\n",
       "      <td>-38.4722</td>\n",
       "      <td>2573.5</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>132.6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74333</th>\n",
       "      <td>320.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>11.0377</td>\n",
       "      <td>85.7500</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>13.6646</td>\n",
       "      <td>69.8889</td>\n",
       "      <td>2610.5</td>\n",
       "      <td>10.3029</td>\n",
       "      <td>102.3056</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>12.4370</td>\n",
       "      <td>132.5833</td>\n",
       "      <td>3246.5</td>\n",
       "      <td>14.9231</td>\n",
       "      <td>301.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78641</th>\n",
       "      <td>338.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1323.5</td>\n",
       "      <td>-2.8163</td>\n",
       "      <td>-19.9444</td>\n",
       "      <td>1793.5</td>\n",
       "      <td>-4.7673</td>\n",
       "      <td>-43.4167</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>-3.5660</td>\n",
       "      <td>-43.0278</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>19.0278</td>\n",
       "      <td>3206.0</td>\n",
       "      <td>3.5356</td>\n",
       "      <td>74.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146488</th>\n",
       "      <td>630.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>1294.5</td>\n",
       "      <td>3.5361</td>\n",
       "      <td>15.7500</td>\n",
       "      <td>1749.5</td>\n",
       "      <td>5.9138</td>\n",
       "      <td>75.7500</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>7.5134</td>\n",
       "      <td>116.4722</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>5.6078</td>\n",
       "      <td>88.2778</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>140.0833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x      y  d1sat0   d2sat0     sat0  d1sat1   d2sat1      sat1  \\\n",
       "86881   374.0  226.0  1164.0  -1.4649 -81.3611  1388.5  -5.0537 -166.5000   \n",
       "2815     12.0   62.0   948.0   1.4959  63.4167  1227.0   1.3194   72.0833   \n",
       "74333   320.0  186.0  1806.0  11.0377  85.7500  2227.0  13.6646   69.8889   \n",
       "78641   338.0  450.0  1323.5  -2.8163 -19.9444  1793.5  -4.7673  -43.4167   \n",
       "146488  630.0  656.0  1294.5   3.5361  15.7500  1749.5   5.9138   75.7500   \n",
       "\n",
       "        d1sat2   d2sat2      sat2  d1sat3   d2sat3      sat3  d1sat4   d2sat4  \\\n",
       "86881   1641.0  -7.7735 -224.6389  2602.0 -28.4794 -300.2500  2783.5  -6.1192   \n",
       "2815    1549.0   1.4102   69.5278  1933.0   1.0335  -38.4722  2573.5   7.7750   \n",
       "74333   2610.5  10.3029  102.3056  2850.0  12.4370  132.5833  3246.5  14.9231   \n",
       "78641   2251.0  -3.5660  -43.0278  2674.0   0.8013   19.0278  3206.0   3.5356   \n",
       "146488  2248.0   7.5134  116.4722  2572.0   5.6078   88.2778  2898.0   0.8447   \n",
       "\n",
       "            sat4  \n",
       "86881  -246.1944  \n",
       "2815    132.6111  \n",
       "74333   301.0833  \n",
       "78641    74.8889  \n",
       "146488  140.0833  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Define model parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "# Define how many inputs and outputs are in our neural network\n",
    "number_of_inputs =17\n",
    "number_of_outputs =1\n",
    "\n",
    "# Define how many neurons we want in each layer of our neural network\n",
    "layer_1_nodes =50\n",
    "layer_2_nodes =100\n",
    "layer_3_nodes =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Zikei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(name=\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "    \n",
    "    # Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(name=\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(name=\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(name=\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "#     cost = tf.reduce_sum(tf.square(tf.subtract(prediction, Y)))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Training Cost: 0.1514832079410553  Testing Cost: 0.15186455845832825\n",
      "Epoch: 50 - Training Cost: 0.01711115799844265  Testing Cost: 0.016743283718824387\n",
      "Epoch: 100 - Training Cost: 0.01667560450732708  Testing Cost: 0.01632450334727764\n",
      "Epoch: 150 - Training Cost: 0.016507413238286972  Testing Cost: 0.01616845466196537\n",
      "Epoch: 200 - Training Cost: 0.016260668635368347  Testing Cost: 0.015940232202410698\n",
      "Epoch: 250 - Training Cost: 0.015912989154458046  Testing Cost: 0.015612022019922733\n",
      "Epoch: 300 - Training Cost: 0.015566087327897549  Testing Cost: 0.015260829590260983\n",
      "Epoch: 350 - Training Cost: 0.0152443153783679  Testing Cost: 0.014927802607417107\n",
      "Epoch: 400 - Training Cost: 0.015071108937263489  Testing Cost: 0.014752507209777832\n",
      "Epoch: 450 - Training Cost: 0.014868408441543579  Testing Cost: 0.014551554806530476\n",
      "Epoch: 500 - Training Cost: 0.014837158843874931  Testing Cost: 0.014507506974041462\n",
      "Epoch: 550 - Training Cost: 0.014762189239263535  Testing Cost: 0.014450465328991413\n",
      "Epoch: 600 - Training Cost: 0.01578417606651783  Testing Cost: 0.015483787283301353\n",
      "Epoch: 650 - Training Cost: 0.014645569026470184  Testing Cost: 0.014369729906320572\n",
      "Epoch: 700 - Training Cost: 0.014555342495441437  Testing Cost: 0.014281346462666988\n",
      "Epoch: 750 - Training Cost: 0.014506211504340172  Testing Cost: 0.014246588572859764\n",
      "Epoch: 800 - Training Cost: 0.014714173041284084  Testing Cost: 0.014441660605370998\n",
      "Epoch: 850 - Training Cost: 0.01452130638062954  Testing Cost: 0.01427198201417923\n",
      "Epoch: 900 - Training Cost: 0.014471366070210934  Testing Cost: 0.014242753386497498\n",
      "Epoch: 950 - Training Cost: 0.014413884840905666  Testing Cost: 0.014214112423360348\n",
      "Training is complete!\n",
      "Final Training cost: 0.014459401369094849\n",
      "Final Testing cost: 0.014227624982595444\n",
      "The actual phreatophyte of location #1 were $-0.0\n",
      "Our neural network predicted phreatophyte of $59.601261138916016\n",
      "Model saved: logs/trained_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Initialize a session so that we can run TensorFlow operations\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    training_writer = tf.summary.FileWriter(\"./logs/training\", session.graph)\n",
    "    testing_writer = tf.summary.FileWriter(\"./logs/testing\", session.graph)\n",
    "    \n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "\n",
    "        # Every 5 training steps, log our progress\n",
    "        if epoch % display_step == 0:\n",
    "           # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "            training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "            testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "\n",
    "            # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "            training_writer.add_summary(training_summary, epoch)\n",
    "            testing_writer.add_summary(testing_summary, epoch)\n",
    "\n",
    "            # Print the current training status to the screen\n",
    "            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "\n",
    "    # Training is now complete!\n",
    "    print(\"Training is complete!\")\n",
    "\n",
    "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "    \n",
    "     # Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "      # Pass in the X testing data and run the \"prediciton\" operation\n",
    "    Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n",
    "\n",
    "     # Unscale the data back to it's original units (dollars)\n",
    "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
    "\n",
    "    real_phreat = data['phreat'].values[0]\n",
    "    predicted_phreat = Y_predicted[0][0]\n",
    "\n",
    "    print(\"The actual phreatophyte of location #1 were ${}\".format(real_phreat))\n",
    "    print(\"Our neural network predicted phreatophyte of ${}\".format(predicted_phreat))\n",
    "    \n",
    "    save_path = saver.save(session, \"logs/trained_model.ckpt\")\n",
    "    print(\"Model saved: {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual phreatophyte -0.0   Predicted 59.60126\n",
      "Actual phreatophyte 0.0   Predicted 9.258748\n",
      "Actual phreatophyte 0.0   Predicted -1.5754232\n",
      "Actual phreatophyte 0.0   Predicted 11.110655\n",
      "Actual phreatophyte 0.0   Predicted 27.21364\n",
      "Actual phreatophyte 0.0   Predicted 7.5020056\n",
      "Actual phreatophyte -0.0   Predicted 20.028986\n",
      "Actual phreatophyte -0.0   Predicted 9.05507\n",
      "Actual phreatophyte -0.0   Predicted 1.4092633\n",
      "Actual phreatophyte 0.0   Predicted 150.28369\n",
      "Actual phreatophyte 0.0   Predicted 10.020797\n",
      "Actual phreatophyte -0.0   Predicted 24.780796\n",
      "Actual phreatophyte -0.0   Predicted 12.108165\n",
      "Actual phreatophyte -0.0   Predicted 5.380642\n",
      "Actual phreatophyte 0.0   Predicted 5.9178343\n",
      "Actual phreatophyte 0.0   Predicted 80.06263\n",
      "Actual phreatophyte 0.0   Predicted 11.685562\n",
      "Actual phreatophyte -0.0   Predicted 21.71754\n",
      "Actual phreatophyte -0.0   Predicted 10.878647\n",
      "Actual phreatophyte 0.1083   Predicted -1.7334247\n",
      "Actual phreatophyte -18.7107   Predicted 6.0707755\n",
      "Actual phreatophyte 4.8255   Predicted 37.780552\n",
      "Actual phreatophyte -0.0001   Predicted 28.94423\n",
      "Actual phreatophyte -0.0   Predicted 51.83935\n",
      "Actual phreatophyte -0.0   Predicted 19.649948\n",
      "Actual phreatophyte 0.0   Predicted 6.150958\n",
      "Actual phreatophyte 0.0   Predicted 13.266957\n",
      "Actual phreatophyte -0.0   Predicted 58.271614\n",
      "Actual phreatophyte -0.0   Predicted 11.149923\n",
      "Actual phreatophyte 0.0   Predicted 15.956733\n",
      "Actual phreatophyte 0.0   Predicted 81.07489\n",
      "Actual phreatophyte -0.0   Predicted 6.0144205\n",
      "Actual phreatophyte 0.0   Predicted 87.6774\n",
      "Actual phreatophyte 0.0   Predicted 17.061918\n",
      "Actual phreatophyte 0.0   Predicted 40.96106\n",
      "Actual phreatophyte -0.0   Predicted 6.1246533\n",
      "Actual phreatophyte -0.0   Predicted 26.288397\n",
      "Actual phreatophyte -0.0   Predicted 4.8254986\n",
      "Actual phreatophyte 0.0   Predicted 27.784628\n",
      "Actual phreatophyte 0.0   Predicted 5.1165776\n",
      "Actual phreatophyte 0.0   Predicted 4.6720595\n",
      "Actual phreatophyte -0.0   Predicted 3.4864514\n",
      "Actual phreatophyte 0.0   Predicted 0.17820464\n",
      "Actual phreatophyte -0.0   Predicted 19.17233\n",
      "Actual phreatophyte -0.0   Predicted 9.831915\n",
      "Actual phreatophyte -0.0   Predicted 49.86351\n",
      "Actual phreatophyte 0.0   Predicted 9.068976\n",
      "Actual phreatophyte 0.0   Predicted -2.6273093\n",
      "Actual phreatophyte -0.0   Predicted 12.048888\n",
      "Actual phreatophyte -0.0   Predicted 16.406113\n",
      "Actual phreatophyte -0.0   Predicted -44.239155\n",
      "Actual phreatophyte 0.0   Predicted 4.811798\n",
      "Actual phreatophyte 0.0   Predicted 7.364591\n",
      "Actual phreatophyte 0.0   Predicted 11.693531\n",
      "Actual phreatophyte -0.0   Predicted 12.559125\n",
      "Actual phreatophyte -0.0   Predicted 11.354192\n",
      "Actual phreatophyte -0.0   Predicted 20.230114\n",
      "Actual phreatophyte 0.0   Predicted 18.524971\n",
      "Actual phreatophyte 0.0   Predicted 3.997074\n",
      "Actual phreatophyte -0.0   Predicted 69.53158\n",
      "Actual phreatophyte -0.0   Predicted 5.626509\n",
      "Actual phreatophyte -0.0   Predicted 27.40875\n",
      "Actual phreatophyte 0.0   Predicted 7.3855762\n",
      "Actual phreatophyte -0.0   Predicted 38.4201\n",
      "Actual phreatophyte -0.0   Predicted 4.845521\n",
      "Actual phreatophyte 0.0   Predicted 24.284718\n",
      "Actual phreatophyte 0.0   Predicted 34.59109\n",
      "Actual phreatophyte -0.0   Predicted 8.544262\n",
      "Actual phreatophyte -0.0   Predicted -0.28165427\n",
      "Actual phreatophyte -0.0   Predicted 24.82565\n",
      "Actual phreatophyte 0.0   Predicted 1.4569386\n",
      "Actual phreatophyte 0.0   Predicted 2.1582887\n",
      "Actual phreatophyte 0.0   Predicted 45.270954\n",
      "Actual phreatophyte -0.0   Predicted 4.9300537\n",
      "Actual phreatophyte -0.0   Predicted 42.37712\n",
      "Actual phreatophyte 0.0   Predicted 22.664831\n",
      "Actual phreatophyte 0.0   Predicted 116.05201\n",
      "Actual phreatophyte 0.0   Predicted 1.9953731\n",
      "Actual phreatophyte -0.0   Predicted -0.19455826\n",
      "Actual phreatophyte -0.0   Predicted 16.668629\n",
      "Actual phreatophyte 0.0   Predicted 15.06504\n",
      "Actual phreatophyte 0.0   Predicted 9.842168\n",
      "Actual phreatophyte -0.0   Predicted 11.748099\n",
      "Actual phreatophyte 0.0   Predicted 11.219394\n",
      "Actual phreatophyte 0.0   Predicted 39.960083\n",
      "Actual phreatophyte 0.0   Predicted 22.595234\n",
      "Actual phreatophyte -0.0   Predicted 1.9391508\n",
      "Actual phreatophyte -0.0   Predicted 6.000574\n",
      "Actual phreatophyte 0.0   Predicted 16.76046\n",
      "Actual phreatophyte 0.0   Predicted 18.87665\n",
      "Actual phreatophyte 0.0   Predicted 20.372417\n",
      "Actual phreatophyte -0.0   Predicted 9.774291\n",
      "Actual phreatophyte 0.0   Predicted 0.06916032\n",
      "Actual phreatophyte 0.0   Predicted 8.812968\n",
      "Actual phreatophyte -0.0   Predicted -0.36860418\n",
      "Actual phreatophyte 0.0   Predicted 4.5211506\n",
      "Actual phreatophyte -0.0   Predicted 12.47798\n",
      "Actual phreatophyte 0.0   Predicted 3.669476\n",
      "Actual phreatophyte 0.0   Predicted 9.476478\n",
      "Actual phreatophyte -0.0   Predicted 106.849945\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print( \"Actual phreatophyte\",data['phreat'].values[i],\"  Predicted\",Y_predicted[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
