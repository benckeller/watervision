{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zikei\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128716 train + 32179 test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv(\"data9.csv\", dtype=float)\n",
    "data=data.dropna(axis=0,how='any')\n",
    "data.phreat[data['phreat']=='-0']=0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>d1prec</th>\n",
       "      <th>d2prec</th>\n",
       "      <th>prec</th>\n",
       "      <th>d1ndvi</th>\n",
       "      <th>d2ndvi</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>d1temp</th>\n",
       "      <th>d2temp</th>\n",
       "      <th>...</th>\n",
       "      <th>d2sat2</th>\n",
       "      <th>sat2</th>\n",
       "      <th>d1sat3</th>\n",
       "      <th>d2sat3</th>\n",
       "      <th>sat3</th>\n",
       "      <th>d1sat4</th>\n",
       "      <th>d2sat4</th>\n",
       "      <th>sat4</th>\n",
       "      <th>gwlvl</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86881</th>\n",
       "      <td>374.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>5.0365</td>\n",
       "      <td>11.3205</td>\n",
       "      <td>-6.9401</td>\n",
       "      <td>581.8333</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.7735</td>\n",
       "      <td>-224.6389</td>\n",
       "      <td>2602.0</td>\n",
       "      <td>-28.4794</td>\n",
       "      <td>-300.2500</td>\n",
       "      <td>2783.5</td>\n",
       "      <td>-6.1192</td>\n",
       "      <td>-246.1944</td>\n",
       "      <td>58.1927</td>\n",
       "      <td>-0.0356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>16.2615</td>\n",
       "      <td>12.9247</td>\n",
       "      <td>174.3333</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4102</td>\n",
       "      <td>69.5278</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1.0335</td>\n",
       "      <td>-38.4722</td>\n",
       "      <td>2573.5</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>132.6111</td>\n",
       "      <td>29.0500</td>\n",
       "      <td>-0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74333</th>\n",
       "      <td>320.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.3204</td>\n",
       "      <td>2.6022</td>\n",
       "      <td>10.5640</td>\n",
       "      <td>5.7564</td>\n",
       "      <td>-10.1111</td>\n",
       "      <td>983.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>...</td>\n",
       "      <td>10.3029</td>\n",
       "      <td>102.3056</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>12.4370</td>\n",
       "      <td>132.5833</td>\n",
       "      <td>3246.5</td>\n",
       "      <td>14.9231</td>\n",
       "      <td>301.0833</td>\n",
       "      <td>84.9648</td>\n",
       "      <td>-0.0254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78641</th>\n",
       "      <td>338.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>-1.9883</td>\n",
       "      <td>13.9865</td>\n",
       "      <td>15.7853</td>\n",
       "      <td>143.8889</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.5660</td>\n",
       "      <td>-43.0278</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>19.0278</td>\n",
       "      <td>3206.0</td>\n",
       "      <td>3.5356</td>\n",
       "      <td>74.8889</td>\n",
       "      <td>171.6733</td>\n",
       "      <td>-0.5520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146488</th>\n",
       "      <td>630.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>-0.0243</td>\n",
       "      <td>-4.1178</td>\n",
       "      <td>7.3040</td>\n",
       "      <td>-2.0258</td>\n",
       "      <td>-113.2778</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5134</td>\n",
       "      <td>116.4722</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>5.6078</td>\n",
       "      <td>88.2778</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>140.0833</td>\n",
       "      <td>117.0159</td>\n",
       "      <td>0.0123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x      y  d1prec  d2prec     prec   d1ndvi    d2ndvi    ndvi  \\\n",
       "86881   374.0  226.0  0.3579  5.0365  11.3205  -6.9401  581.8333  3785.0   \n",
       "2815     12.0   62.0  0.0903  0.4562  16.2615  12.9247  174.3333  2497.0   \n",
       "74333   320.0  186.0  0.3204  2.6022  10.5640   5.7564  -10.1111   983.0   \n",
       "78641   338.0  450.0  0.0739 -1.9883  13.9865  15.7853  143.8889  1679.0   \n",
       "146488  630.0  656.0 -0.0243 -4.1178   7.3040  -2.0258 -113.2778  1132.0   \n",
       "\n",
       "        d1temp  d2temp  ...   d2sat2      sat2  d1sat3   d2sat3      sat3  \\\n",
       "86881   0.0175  0.3377  ...  -7.7735 -224.6389  2602.0 -28.4794 -300.2500   \n",
       "2815    0.0406  0.6040  ...   1.4102   69.5278  1933.0   1.0335  -38.4722   \n",
       "74333   0.0080  0.2680  ...  10.3029  102.3056  2850.0  12.4370  132.5833   \n",
       "78641   0.0167  0.3732  ...  -3.5660  -43.0278  2674.0   0.8013   19.0278   \n",
       "146488  0.0158  0.8025  ...   7.5134  116.4722  2572.0   5.6078   88.2778   \n",
       "\n",
       "        d1sat4   d2sat4      sat4     gwlvl   truth  \n",
       "86881   2783.5  -6.1192 -246.1944   58.1927 -0.0356  \n",
       "2815    2573.5   7.7750  132.6111   29.0500 -0.0012  \n",
       "74333   3246.5  14.9231  301.0833   84.9648 -0.0254  \n",
       "78641   3206.0   3.5356   74.8889  171.6733 -0.5520  \n",
       "146488  2898.0   0.8447  140.0833  117.0159  0.0123  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_training = train_set.drop(['phreat','x','y','d1ndwi','d2ndwi','d1evi','d2evi','d1prec','d2prec','d1ndvi','d2ndvi','d1temp','d2temp','gwlvl','t1','t2','d1sat0','d2sat0','d1sat1','d2sat1','d1sat2','d2sat2','d1sat3','d2sat3','d1sat4','d2sat4'], axis=1)\n",
    "X_training = train_set.drop(['phreat','x','y'],axis=1)\n",
    "Y_training = train_set [['phreat']].values\n",
    "\n",
    "#X_testing = test_set.drop(['phreat','x','y','d1ndwi','d2ndwi','d1evi','d2evi','d1prec','d2prec','d1ndvi','d2ndvi','d1temp','d2temp','gwlvl','t1','t2','d1sat0','d2sat0','d1sat1','d2sat1','d1sat2','d2sat2','d1sat3','d2sat3','d1sat4','d2sat4'], axis=1)\n",
    "X_testing = test_set.drop(['phreat','x','y'],axis=1)\n",
    "Y_testing = test_set [['phreat']].values\n",
    "\n",
    "#X_final = data.drop(['phreat','x','y','d1ndwi','d2ndwi','d1evi','d2evi','d1prec','d2prec','d1ndvi','d2ndvi','d1temp','d2temp','gwlvl','t1','t2','d1sat0','d2sat0','d1sat1','d2sat1','d1sat2','d2sat2','d1sat3','d2sat3','d1sat4','d2sat4'], axis=1)\n",
    "X_final = data.drop(['phreat','x','y'],axis=1)\n",
    "Y_final = data [['phreat']].values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)\n",
    "\n",
    "X_scaled_final = X_scaler.transform(X_final)\n",
    "Y_scaled_final = Y_scaler.transform(Y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128716, 29)\n",
      "(128716, 1)\n",
      "(32179, 29)\n",
      "(32179, 1)\n",
      "(160895, 29)\n",
      "(160895, 1)\n",
      "Note: Y values were scaled by multiplying by 0.0022438313 and adding 0.2196\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled_training.shape)\n",
    "print(Y_scaled_training.shape)\n",
    "\n",
    "print(X_scaled_testing.shape)\n",
    "print(Y_scaled_testing.shape)\n",
    "\n",
    "\n",
    "print(X_scaled_final.shape)\n",
    "print(Y_scaled_final.shape)\n",
    "\n",
    "print(\"Note: Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0], Y_scaler.min_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73624776 0.7718208  0.0739537  ... 0.38816272 0.12967194 0.61710488]\n",
      " [0.66677916 0.69671594 0.12885644 ... 0.40389401 0.09013452 0.61967952]\n",
      " [0.72651281 0.73190469 0.06554772 ... 0.41089043 0.16599321 0.61786829]\n",
      " ...\n",
      " [0.65784897 0.62880788 0.1041441  ... 0.39995801 0.39563265 0.61875145]\n",
      " [0.58908128 0.60185061 0.08145963 ... 0.40375788 0.2375877  0.62183503]\n",
      " [0.62319254 0.61294998 0.0864821  ... 0.40604657 0.38525863 0.62990323]]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1prec</th>\n",
       "      <th>d2prec</th>\n",
       "      <th>prec</th>\n",
       "      <th>d1ndvi</th>\n",
       "      <th>d2ndvi</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>d1temp</th>\n",
       "      <th>d2temp</th>\n",
       "      <th>temp</th>\n",
       "      <th>evapot</th>\n",
       "      <th>...</th>\n",
       "      <th>d2sat2</th>\n",
       "      <th>sat2</th>\n",
       "      <th>d1sat3</th>\n",
       "      <th>d2sat3</th>\n",
       "      <th>sat3</th>\n",
       "      <th>d1sat4</th>\n",
       "      <th>d2sat4</th>\n",
       "      <th>sat4</th>\n",
       "      <th>gwlvl</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86881</th>\n",
       "      <td>0.3579</td>\n",
       "      <td>5.0365</td>\n",
       "      <td>11.3205</td>\n",
       "      <td>-6.9401</td>\n",
       "      <td>581.8333</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>11.4500</td>\n",
       "      <td>3.1640</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.7735</td>\n",
       "      <td>-224.6389</td>\n",
       "      <td>2602.0</td>\n",
       "      <td>-28.4794</td>\n",
       "      <td>-300.2500</td>\n",
       "      <td>2783.5</td>\n",
       "      <td>-6.1192</td>\n",
       "      <td>-246.1944</td>\n",
       "      <td>58.1927</td>\n",
       "      <td>-0.0356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>16.2615</td>\n",
       "      <td>12.9247</td>\n",
       "      <td>174.3333</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>6.2135</td>\n",
       "      <td>6.0879</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4102</td>\n",
       "      <td>69.5278</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1.0335</td>\n",
       "      <td>-38.4722</td>\n",
       "      <td>2573.5</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>132.6111</td>\n",
       "      <td>29.0500</td>\n",
       "      <td>-0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74333</th>\n",
       "      <td>0.3204</td>\n",
       "      <td>2.6022</td>\n",
       "      <td>10.5640</td>\n",
       "      <td>5.7564</td>\n",
       "      <td>-10.1111</td>\n",
       "      <td>983.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>10.8595</td>\n",
       "      <td>2.8543</td>\n",
       "      <td>...</td>\n",
       "      <td>10.3029</td>\n",
       "      <td>102.3056</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>12.4370</td>\n",
       "      <td>132.5833</td>\n",
       "      <td>3246.5</td>\n",
       "      <td>14.9231</td>\n",
       "      <td>301.0833</td>\n",
       "      <td>84.9648</td>\n",
       "      <td>-0.0254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78641</th>\n",
       "      <td>0.0739</td>\n",
       "      <td>-1.9883</td>\n",
       "      <td>13.9865</td>\n",
       "      <td>15.7853</td>\n",
       "      <td>143.8889</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>8.6485</td>\n",
       "      <td>6.3081</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.5660</td>\n",
       "      <td>-43.0278</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>19.0278</td>\n",
       "      <td>3206.0</td>\n",
       "      <td>3.5356</td>\n",
       "      <td>74.8889</td>\n",
       "      <td>171.6733</td>\n",
       "      <td>-0.5520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146488</th>\n",
       "      <td>-0.0243</td>\n",
       "      <td>-4.1178</td>\n",
       "      <td>7.3040</td>\n",
       "      <td>-2.0258</td>\n",
       "      <td>-113.2778</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>11.1185</td>\n",
       "      <td>4.0409</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5134</td>\n",
       "      <td>116.4722</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>5.6078</td>\n",
       "      <td>88.2778</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>140.0833</td>\n",
       "      <td>117.0159</td>\n",
       "      <td>0.0123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        d1prec  d2prec     prec   d1ndvi    d2ndvi    ndvi  d1temp  d2temp  \\\n",
       "86881   0.3579  5.0365  11.3205  -6.9401  581.8333  3785.0  0.0175  0.3377   \n",
       "2815    0.0903  0.4562  16.2615  12.9247  174.3333  2497.0  0.0406  0.6040   \n",
       "74333   0.3204  2.6022  10.5640   5.7564  -10.1111   983.0  0.0080  0.2680   \n",
       "78641   0.0739 -1.9883  13.9865  15.7853  143.8889  1679.0  0.0167  0.3732   \n",
       "146488 -0.0243 -4.1178   7.3040  -2.0258 -113.2778  1132.0  0.0158  0.8025   \n",
       "\n",
       "           temp  evapot  ...   d2sat2      sat2  d1sat3   d2sat3      sat3  \\\n",
       "86881   11.4500  3.1640  ...  -7.7735 -224.6389  2602.0 -28.4794 -300.2500   \n",
       "2815     6.2135  6.0879  ...   1.4102   69.5278  1933.0   1.0335  -38.4722   \n",
       "74333   10.8595  2.8543  ...  10.3029  102.3056  2850.0  12.4370  132.5833   \n",
       "78641    8.6485  6.3081  ...  -3.5660  -43.0278  2674.0   0.8013   19.0278   \n",
       "146488  11.1185  4.0409  ...   7.5134  116.4722  2572.0   5.6078   88.2778   \n",
       "\n",
       "        d1sat4   d2sat4      sat4     gwlvl   truth  \n",
       "86881   2783.5  -6.1192 -246.1944   58.1927 -0.0356  \n",
       "2815    2573.5   7.7750  132.6111   29.0500 -0.0012  \n",
       "74333   3246.5  14.9231  301.0833   84.9648 -0.0254  \n",
       "78641   3206.0   3.5356   74.8889  171.6733 -0.5520  \n",
       "146488  2898.0   0.8447  140.0833  117.0159  0.0123  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Define model parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 2000\n",
    "display_step = 100\n",
    "\n",
    "# Define how many inputs and outputs are in our neural network\n",
    "number_of_inputs =29\n",
    "number_of_outputs =1\n",
    "\n",
    "# Define how many neurons we want in each layer of our neural network\n",
    "layer_1_nodes =100\n",
    "layer_2_nodes =500\n",
    "layer_3_nodes =500\n",
    "layer_4_nodes =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Zikei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(name=\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "    \n",
    "    # Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(name=\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(name=\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "# Layer 4\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(name=\"weights4\", shape=[layer_3_nodes, layer_4_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[layer_4_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_4_output = tf.nn.relu(tf.matmul(layer_3_output, weights) + biases)\n",
    "    \n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(name=\"weights5\", shape=[layer_4_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases5\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_4_output, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "#    cost = tf.reduce_sum(tf.square(tf.subtract(prediction, Y)))\n",
    "#    cross_entropy = -tf.reduce_sum(Y*tf.log(prediction))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
    "#with tf.variable_scope('accuracy'):\n",
    " #   correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(Y,1))\n",
    "  #  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Training Cost: 36.5207405090332  Testing Cost: 36.559776306152344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-029ba358b2cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Feed in the training data and do one step of neural network training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_scaled_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_scaled_training\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Every 100 training steps, log our progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize a session so that we can run TensorFlow operations\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    #training_writer = tf.summary.FileWriter('./logs/training', session.graph)\n",
    "    #testing_writer = tf.summary.FileWriter('./logs/testing', session.graph)\n",
    "\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "\n",
    "        # Every 100 training steps, log our progress\n",
    "        if epoch % 100 == 0:\n",
    "            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "            training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_scaled_training, Y:Y_scaled_training})\n",
    "            testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: X_scaled_testing, Y:Y_scaled_testing})\n",
    "            #testing_accuracy = session.run(accuracy, feed_dict={X: X_scaled_testing, Y:Y_scaled_testing})\n",
    "        # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "            #training_writer.add_summary(training_summary, epoch)\n",
    "            #testing_writer.add_summary(testing_summary, epoch)\n",
    "            \n",
    "            # Print the current training status to the screen\n",
    "            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "            #print(\"Epoch: {} -  Accuracy:{}\".format(epoch, testing_accuracy))\n",
    "\n",
    "    # Training is now complete!\n",
    "\n",
    "    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "    #final_test_acc= session.run(accuracy, feed_dict={X: X_scaled_final, Y: Y_scaled_final})\n",
    "    \n",
    "    #print(\"test accuracy\",final_test_acc)\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "\n",
    "    # Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "    \n",
    "    \n",
    "    # Now that the neural network is trained, let's use it to make predictions for our test data\n",
    "    # Pass in the X testing data and run the \"prediciton\" operation\n",
    "    Y_predicted_test_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n",
    "\n",
    "    # Unscale the data back to it's original units (dollars)\n",
    "    Y_test_predicted = Y_scaler.inverse_transform(Y_predicted_test_scaled)\n",
    "    \n",
    "    # Now that the neural network is trained, let's use it to make predictions for our test data\n",
    "    # Pass in the X testing data and run the \"prediciton\" operation\n",
    "    Y_predicted_train_scaled = session.run(prediction, feed_dict={X: X_scaled_training})\n",
    "\n",
    "    # Unscale the data back to it's original units (dollars)\n",
    "    Y_train_predicted = Y_scaler.inverse_transform(Y_predicted_train_scaled)\n",
    "    \n",
    "    \n",
    "    # Pass in the X testing data and run the \"prediciton\" operation\n",
    "    Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_final})\n",
    "\n",
    "    # Unscale the data back to it's original units (dollars)\n",
    "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print( \"Actual phreatophyte\",data['phreat'].values[i],\"  Predicted\",Y_predicted[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_final=Y_final.flatten()\n",
    "data.plot(kind=\"scatter\",x=\"y\",y=\"x\",alpha=0.4,c=Y_final,figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Predicted=Y_predicted.flatten()\n",
    "data.plot(kind=\"scatter\",x=\"y\",y=\"x\",alpha=0.4,c=Predicted,figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(Predicted,Y_final))/np.std(Y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_Train=Y_train_predicted.flatten()\n",
    "np.sqrt(mean_squared_error(Predicted_Train,Y_training))/np.std(Y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_Test=Y_test_predicted.flatten()\n",
    "np.sqrt(mean_squared_error(Predicted_Test,Y_testing))/np.std(Y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
